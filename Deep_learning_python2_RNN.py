# -*- coding: utf-8 -*-
"""Deep_Learning_Project_Data_Preprocessing_RNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1On2zGsq0KtLLHFOSeb3Aw7r4Z_7Z5Keu

# Credit Score Classification with RNN
# Sepideh Forouzi
# I. Introduction

The classification of credit scores is a critical task in the financial services industry, enabling banks and lending institutions to assess the creditworthiness of individuals. Traditional methods often rely on manual processes and rule-based systems, which are time-consuming and prone to error. With recent advancements in Artificial Intelligence (AI) and Machine Learning (ML), particularly Deep Learning, these processes can be automated to significantly improve accuracy and efficiency.

---

## 1. Problem Statement

Based on data collected over the past few years by a global finance company, management aims to build an intelligent system to automatically segregate individuals into credit score brackets, thereby reducing manual effort.  
The objective is to develop an intelligent classification system that categorizes individuals into predefined credit score groups.

---

## 2. Project Aim

This project aims to design and implement a **Neural Network–based multi-class classification model** to categorize individuals into three credit score brackets: **Poor**, **Standard**, and **Good**.  
By leveraging data-driven insights, the model seeks to minimize manual evaluation efforts and enhance decision-making in credit risk assessment.

---

## 3. Project Scope

The primary scope of this project includes:

- Developing an intelligent classification system for predefined credit score brackets  
- Reducing manual effort through automated machine learning–based classification  
- Adopting Neural Network models for multi-class classification to capture complex, non-linear relationships within the data  

This system can support financial institutions in **risk management**, **loan approval**, and **customer segmentation** by providing scalable and accurate predictions.

---

## 4. Dataset

The dataset was obtained from an open Kaggle competition provided by a global finance company. It contains customer banking details and extensive credit-related information.

- **Dataset size:** 100,000 rows  
- **Total features:** 27  
- **Removed redundant columns:** `ID`, `Customer_ID`, `Name`, `SSN`, `Month`  
- **Feature composition:**  
  - 17 numerical features  
  - 9 categorical features  
- **Target labels:**  
  - `Poor`  
  - `Standard`  
  - `Good`

**Data source:**  
https://www.kaggle.com/datasets/parisrohan/credit-score-classification

---

## 5. Tasks

- Develop, train, and refine Neural Network models  
- Perform multi-class classification into three credit score categories:  
  **Poor**, **Standard**, and **Good**

---

## 6. Executive Summary

This project developed and compared multiple machine learning and deep learning models to automate credit score classification into three categories: **Poor**, **Standard**, and **Good**. Following extensive data preprocessing and model evaluation, the **EmbedMLP Neural Network** achieved the best overall performance, with approximately **85.7% accuracy** and a **Macro-F1 score of 0.857**.

The EmbedMLP model outperformed traditional approaches such as Logistic Regression, Decision Tree, and SVM, as well as more complex architectures including RNNs and Transformers. Its ability to effectively handle both numerical and categorical features resulted in strong generalization and balanced classification across all classes.

These results demonstrate the model’s strong potential for real-world credit risk assessment, offering a scalable and accurate solution to reduce manual evaluation efforts and support informed financial decision-making.
"""

#import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.utils import to_categorical

"""##Data Inspection"""

# from google.colab import drive
# drive.mount('/content/drive')

#Load dataset
# test_data = pd.read_csv('/content/drive/MyDrive/test.csv')
# data = pd.read_csv('/content/drive/MyDrive/train.csv')
data = pd.read_csv('train.csv')

# data.head(7)

round(data.describe())

data.info()

# Drop unnecessaries
uneccessaries = ['ID','Customer_ID', 'Name', 'SSN', 'Month']
data.drop(uneccessaries , axis=1 , inplace=True)

# Define numeric and categorical column lists globally
numeric_like_cols = [
    "Age", "Annual_Income", "Num_of_Loan", "Num_of_Delayed_Payment",
    "Changed_Credit_Limit", "Outstanding_Debt",
    "Amount_invested_monthly", "Monthly_Balance",
    "Monthly_Inhand_Salary", "Num_Bank_Accounts", "Num_Credit_Card",
    "Interest_Rate", "Delay_from_due_date", "Num_Credit_Inquiries",
    "Credit_Utilization_Ratio", "Total_EMI_per_month", "Credit_History_Age"
]

categorical_cols = [
    "Occupation", "Type_of_Loan", "Credit_Mix",
    "Payment_of_Min_Amount", "Payment_Behaviour", "Credit_Score"
]

for col in numeric_like_cols:
    if col in data.columns:
        # Remove all non-numeric characters except digits, decimal, minus
        data[col] = data[col].astype(str).str.replace(r"[^0-9\.-]", "", regex=True)
        # Convert to numeric
        data[col] = pd.to_numeric(data[col], errors="coerce")

for col in categorical_cols:
    if col in data.columns:
        # Replace placeholder values
        data[col] = data[col].replace(["_", "_______", "NA", "nan", "NaN", "!@9#%8"], np.nan)

        # Remove leading/trailing spaces and normalize text
        data[col] = data[col].astype(str).str.strip().str.replace("_", " ")

#Check the percentage of missing value
round(data.isnull().mean()*100)

round(data.describe())

#Check dupplicate
print(data.duplicated().sum())

"""##Exploratory analysis of the  dataset"""

#Explore the distribution of numeric variables:
def plot_histogram(df, columns, rows=2, cols=3):
    fig, axes = plt.subplots(rows, cols, figsize=(5*cols, 4*rows))
    axes = axes.flatten()

    for i, column in enumerate(columns):
      if i < len(axes):
        sns.histplot(df[column], kde=True, ax=axes[i], bins=100)
        axes[i].set_title(column)
        axes[i].set_xlabel('')

    for j in range(i+1, len(axes)):
        fig.delaxes(axes[j])

    plt.tight_layout()
    plt.show()

# Select only the columns from numeric_like_cols that are actually numeric
numeric_cols_for_plotting = data[numeric_like_cols].select_dtypes(include=np.number).columns.tolist()

plot_histogram(data, numeric_cols_for_plotting, rows=5, cols=4)

"""##Pre-processing data"""

#Missing values handling:

# Ensure all numeric-like columns are numeric before filling missing values
for col in numeric_like_cols:
    if col in data.columns:
        # Remove all non-numeric characters except digits, decimal, minus
        data[col] = data[col].astype(str).str.replace(r"[^0-9\.-]", "", regex=True)
        # Convert to numeric, coercing errors to NaN
        data[col] = pd.to_numeric(data[col], errors="coerce")

#Filling by MEAN for: 'Monthly_Inhand_Salary','Num_of_Delayed_Payment', 'Changed_Credit_Limit'
fill_by_mean = ['Monthly_Inhand_Salary','Num_of_Delayed_Payment', 'Changed_Credit_Limit']
for col in fill_by_mean:
    if col in data.columns:
      # Fill NaNs with column mean
      data[col] = data[col].fillna(data[col].mean())

#------------------------------------------------------------------------------

#Filling by MEDIAN for: 'Annual_Income', 'Interest_Rate', 'Total_EMI_per_month'
fill_by_median = ['Annual_Income', 'Interest_Rate', 'Total_EMI_per_month']
for col in fill_by_median:
    if col in data.columns:
      # Fill NaNs with median
      data[col] = data[col].fillna(data[col].median())

#As the histogram shown we can see outliers
#Using the IQR to detect outliers and remove with
def remove_outliers(df, columns):
    for column in columns:
        Q1 = df[column].quantile(0.25)
        Q3 = df[column].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]
    return df

data = remove_outliers(data, numeric_like_cols)

plot_histogram(data, numeric_cols_for_plotting, rows=5, cols=4)

#Explore the categorical columns:
print(data['Credit_Score'].value_counts())
sns.countplot(data['Credit_Score'])

for col in categorical_cols:
    print(data[col].value_counts())

print(data.columns)

# One-Hot Encoding for small-cardinality columns
one_hot_cols = ['Occupation', 'Credit_Mix', 'Payment_of_Min_Amount', 'Payment_Behaviour']
data = pd.get_dummies(data, columns=one_hot_cols, dummy_na=True)

# Label Encoding for high-cardinality columns
le = LabelEncoder()
data['Type_of_Loan'] = data['Type_of_Loan'].fillna('Unknown')
data['Type_of_Loan'] = le.fit_transform(data['Type_of_Loan'])

#Extract the data into csv
data.to_csv('processed_data.csv', index=False)

#Download the processed data
from google.colab import files
files.download('processed_data.csv')

processed_data = pd.read_csv('processed_data.csv')

processed_data.info()

X = processed_data.drop('Credit_Score', axis=1)

#label encode for y
le = LabelEncoder()
y = le.fit_transform(processed_data['Credit_Score'])

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#StandardScaler
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train[numeric_like_cols] = scaler.fit_transform(X_train[numeric_like_cols])
X_test[numeric_like_cols] = scaler.transform(X_test[numeric_like_cols])

"""##Machine Learning Algorithms for classification approaches

Using Logistics Regression



Using Support Vector Machine


Using Decision Tree
"""

#Logistics Regression
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

lr = LogisticRegression(max_iter=1000)
lr.fit(X_train, y_train)
y_pred = lr.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")

#Classification matrix
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False)
plt

#Decision Tree Classifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report

dt = DecisionTreeClassifier()
dt.fit(X_train, y_train)
y_pred = dt.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")

#Confussion matrix
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.show()

#Support Vector Machine
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report

svm = SVC()
svm.fit(X_train, y_train)
y_pred = svm.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")

#COnfussion matrix
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.show()

"""##Build the feedforward neural network for classification"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.metrics import Accuracy, AUC

#Add the model
model = Sequential()

#Add input layer
model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))

#Add hidden layers
model.add(Dropout(0.3))
model.add(Dense(32, activation='relu'))

#Add output layer
#3 classes with softmax activation function
model.add(Dense(3, activation='softmax'))

#Compile the model
model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'] )

#Add early stopping
es = EarlyStopping( monitor='val_loss',   # monitor validation loss
                    patience=5,           # stop if no improvement after 5 epochs
                    restore_best_weights=True)

#Add the model
model = Sequential()

#Add input layer
model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))

#Add hidden layers
model.add(Dropout(0.3))
model.add(Dense(32, activation='relu'))

#Add output layer
#3 classes with softmax activation function
model.add(Dense(3, activation='softmax'))

#Compile the model
model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'] )

#Add early stopping
es = EarlyStopping( monitor='val_loss',   # monitor validation loss
                    patience=5,           # stop if no improvement after 5 epochs
                    restore_best_weights=True)

#Train the model
model.fit(
    X_train, y_train,
    epochs=100,
    batch_size=32,
    validation_split=0.2,
    callbacks=[es],
    verbose=1
)

"""MOdle enhancement for this model has been completed separatedly on another notebook"""

# Get predictions (from probabilities to class indices)
y_pred_probs = model.predict(X_test)
y_pred = np.argmax(y_pred_probs, axis=1)  # Convert softmax output to class indices

# y_test is already integer labels, no need for np.argmax
y_true = y_test

# Classification report
from sklearn.metrics import classification_report, confusion_matrix
print("\nClassification Report:")
print(classification_report(y_true, y_pred))

# Confusion matrix
import seaborn as sns
import matplotlib.pyplot as plt

cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()

from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import label_binarize
import matplotlib.pyplot as plt
import numpy as np

# y_test is 1D integer labels
# y_pred_probs is model.predict(X_test), shape (n_samples, n_classes)

# Binarize the true labels for one-vs-rest ROC
y_test_bin = label_binarize(y_test, classes=np.unique(y_test))
n_classes = y_test_bin.shape[1]

plt.figure(figsize=(10, 8))

# Plot ROC curve for each class
for i in range(n_classes):
    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_pred_probs[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f'Class {i} (AUC = {roc_auc:.2f})')

# Plot the random guess line
plt.plot([0, 1], [0, 1], 'k--', label='Random guess')

plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve - One-vs-Rest')
plt.legend(loc='lower right')
plt.grid(True)
plt.show()

# Assuming loss, accuracy, y_true, and y_pred are available from cell HP2AoML3IKko
from sklearn.metrics import accuracy_score, classification_report


loss, accuracy = model.evaluate(X_test, y_test)
print("--- Final Model Evaluation ---")
print(f"Test Loss: {loss:.4f}")
print(f"Test Accuracy: {accuracy:.4f}")

print("\nClassification Report:")
print(classification_report(y_true, y_pred))

# If ROC AUC values are needed, you would calculate them here as done in cell mDpn1CZdThss
# and print them. For example:
# from sklearn.metrics import roc_curve, auc
# from sklearn.preprocessing import label_binarize
# import numpy as np
#
# y_test_bin = label_binarize(y_true, classes=np.unique(y_true))
# n_classes = y_test_bin.shape[1]
#
# print("\nROC AUC per class (One-vs-Rest):")
# for i in range(n_classes):
#     fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_pred_probs[:, i]) # Assuming y_pred_probs from HP2AoML3IKko
#     roc_auc = auc(fpr, tpr)
#     print(f"  Class {i}: {roc_auc:.4f}")

import tensorflow as tf
from tensorflow.keras import Model
from tensorflow.keras.layers import LSTM, Dropout, Dense
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping

class RNNModel(Model):
    def __init__(self, num_classes=3, lstm_units=64, hidden_units=32, dropout_rate=0.3):
        super(RNNModel, self).__init__()
        # Layers
        self.lstm = LSTM(lstm_units, activation="tanh")
        self.dropout = Dropout(dropout_rate)
        self.hidden = Dense(hidden_units, activation="relu")
        self.output_layer = Dense(num_classes, activation="softmax")

    def call(self, inputs, training=False):
        x = self.lstm(inputs)
        if training:
            x = self.dropout(x, training=training)
        x = self.hidden(x)
        return self.output_layer(x)


# Instantiate model
model = RNNModel(num_classes=3, lstm_units=64, hidden_units=32, dropout_rate=0.3)

# Compile
model.compile(
    loss="sparse_categorical_crossentropy",
    optimizer=Adam(learning_rate=0.002),
    metrics=["accuracy"]
)

# Early stopping callback
es = EarlyStopping(
    monitor="val_loss",
    patience=5,
    restore_best_weights=True
)

# Reshape X_train and X_test for LSTM input

# Ensure all values are numeric
X_train = X_train.apply(pd.to_numeric, errors="coerce").fillna(0).to_numpy(dtype=np.float32)
X_test = X_test.apply(pd.to_numeric, errors="coerce").fillna(0).to_numpy(dtype=np.float32)

# Reshape for LSTM (samples, timesteps, features)
X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))
X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))

#Compile
model.compile(
    loss="sparse_categorical_crossentropy",
    optimizer=Adam(learning_rate=0.001),
    metrics=["accuracy"]
)


history=model.fit(
    X_train, y_train,
    epochs=100,
    batch_size=32,
    validation_split=0.2,
    callbacks=[es],
    verbose=1)

model.summary()

# Plot Loss
plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title('Model Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

# Plot Accuracy
plt.subplot(1,2,2)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Val Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

best_epoch = history.history['val_accuracy'].index(max(history.history['val_accuracy'])) + 1
plt.axvline(best_epoch, color='r', linestyle='--', label=f'Best Epoch = {best_epoch}')

#Classification matrix
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

y_pred = model.predict(X_test)
y_pred = np.argmax(y_pred, axis=1)

cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.show()

from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score

accuracy = accuracy_score(y_test, y_pred)
recall = recall_score(y_test, y_pred, average='weighted')
precision = precision_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')
print(f"Accuracy: {accuracy}")
print(f"Recall: {recall}")
print(f"Precision: {precision}")
print(f"F1 Score: {f1}")
#

feature_names = X.columns
# Make predictions
y_pred_probs = model.predict(X_test)
y_pred = np.argmax(y_pred_probs, axis=1)

# Convert y_test if it was one-hot encoded
y_true = y_test if len(y_test.shape) == 1 else np.argmax(y_test, axis=1)

# Flatten X_test for LSTM shape (samples × features)
X_test_flat = X_test.reshape(X_test.shape[0], X_test.shape[1])

# Convert back to DataFrame with feature names
df_results = pd.DataFrame(X_test_flat, columns=feature_names)
df_results["true_label"] = y_true
df_results["pred_label"] = y_pred
df_results["correct"] = df_results["true_label"] == df_results["pred_label"]

# Show all features
print("✅ Correctly classified samples (all features):")
print(df_results[df_results["correct"]].head())

print("\n❌ Incorrectly classified samples (all features):")
print(df_results[~df_results["correct"]].head())

"""##RNN Improvement"""

#Add stacked LSTMS layers for deeper sequence learning and batchnormalization
from tensorflow.keras.layers import LSTM, Dropout, Dense, BatchNormalization

#using inheritance
class StackedLSTMRNNModel(RNNModel):
 def __init__(self, num_classes=3, lstm_units=64, hidden_units=32, dropout_rate=0.3):
        super(StackedLSTMRNNModel, self).__init__(num_classes, lstm_units, hidden_units, dropout_rate)

        # Additional LSTM and BatchNorm layers
        self.lstm1 = LSTM(lstm_units, return_sequences=True, activation="tanh")
        self.batchnorm1 = BatchNormalization()
        self.lstm2 = LSTM(32, activation="tanh")
        self.batchnorm2 = BatchNormalization()

        # Redefine or extend hidden layers if desired
        self.hidden = Dense(hidden_units, activation="relu")
        self.output_layer = Dense(num_classes, activation="softmax")

def call(self, inputs, training=False):
        # Pass through stacked LSTMs
        x = self.lstm1(inputs)
        x = self.batchnorm1(x, training=training)
        x = self.lstm2(x)
        x = self.batchnorm2(x, training=training)

        # Dropout + hidden layers
        if training:
            x = self.dropout(x, training=training)
        x = self.hidden(x)
        return self.output_layer(x)

model2 = StackedLSTMRNNModel(num_classes=3, lstm_units=64, hidden_units=32, dropout_rate=0.3)

model2.compile(
    loss="sparse_categorical_crossentropy",
    optimizer=Adam(learning_rate=0.002),
    metrics=["accuracy"]
)

history2=model2.fit(
    X_train, y_train,
    epochs=100,
    batch_size=32,
    validation_split=0.2,
    callbacks=[es],
    verbose=1)

model2.summary()

# Plot Loss
plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
plt.plot(history2.history['loss'], label='Train Loss')
plt.plot(history2.history['val_loss'], label='Val Loss')
plt.title('Model with stacked LSTM and Batch normalization Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

# Plot Accuracy
plt.subplot(1,2,2)
plt.plot(history2.history['accuracy'], label='Train Accuracy')
plt.plot(history2.history['val_accuracy'], label='Val Accuracy')
plt.title('Model with stacked LSTM and Batch normalizationAccuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

best_epoch_2 = history2.history['val_accuracy'].index(max(history2.history['val_accuracy'])) + 1
plt.axvline(best_epoch_2, color='r', linestyle='--', label=f'Best Epoch = {best_epoch}')

y_pred_2 = model2.predict(X_test)
y_pred_2 = np.argmax(y_pred_2, axis=1)

accuracy = accuracy_score(y_test, y_pred_2)
recall = recall_score(y_test, y_pred_2, average='weighted')
precision = precision_score(y_test, y_pred_2, average='weighted')
f1 = f1_score(y_test, y_pred_2, average='weighted')
print(f"Accuracy: {accuracy}")
print(f"Recall: {recall}")
print(f"Precision: {precision}")
print(f"F1 Score: {f1}")

#classification metrix
cm2 = confusion_matrix(y_test, y_pred_2)
plt.figure(figsize=(8, 6))
sns.heatmap(cm2, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.show()

#Add Bidirectional Layer to model with more dropout + batch normalization
from tensorflow.keras.layers import Bidirectional
class IntermediateRNNModel(RNNModel):
    def __init__(self, num_classes=3):
        super(IntermediateRNNModel, self).__init__(num_classes)
        self.lstm1 = Bidirectional(LSTM(64, return_sequences=True))
        self.lstm2 = Bidirectional(LSTM(32))
        self.dropout1 = Dropout(0.3)
        self.hidden = Dense(64, activation="relu")
        self.bn = BatchNormalization()
        self.dropout2 = Dropout(0.3)
        self.output_layer = Dense(num_classes, activation="softmax")

    def call(self, inputs, training=False):
        x = self.lstm1(inputs)
        x = self.lstm2(x)
        if training:
            x = self.dropout1(x, training=training)
        x = self.hidden(x)
        x = self.bn(x, training=training)
        if training:
            x = self.dropout2(x, training=training)
        return self.output_layer(x)

model3 = IntermediateRNNModel(num_classes=3)

model3.compile(
    loss="sparse_categorical_crossentropy",
    optimizer=Adam(learning_rate=0.002),
    metrics=["accuracy"]
)

history3 = model3.fit(
    X_train, y_train,
    epochs=100,
    batch_size=32,
    validation_split=0.2,
    callbacks=[es],
    verbose=1
)

y_pred_3 = model3.predict(X_test)
y_pred_3 = np.argmax(y_pred_3, axis=1)

accuracy = accuracy_score(y_test, y_pred_3)
recall = recall_score(y_test, y_pred_3, average='weighted')
precision = precision_score(y_test, y_pred_3, average='weighted')
f1 = f1_score(y_test, y_pred_3, average='weighted')
print(f"Accuracy: {accuracy}")
print(f"Recall: {recall}")
print(f"Precision: {precision}")
print(f"F1 Score: {f1}")

# Plot Loss
plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
plt.plot(history3.history['loss'], label='Train Loss')
plt.plot(history3.history['val_loss'], label='Val Loss')
plt.title('Model with stacked LSTM, Bidirectional and Batch normalization Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

# Plot Accuracy
plt.subplot(1,2,2)
plt.plot(history3.history['accuracy'], label='Train Accuracy')
plt.plot(history3.history['val_accuracy'], label='Val Accuracy')
plt.title('Model with stacked LSTM, , Bidirectional and Batch normalization Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

best_epoch_3 = history3.history['val_accuracy'].index(max(history3.history['val_accuracy'])) + 1
plt.axvline(best_epoch_3, color='r', linestyle='--', label=f'Best Epoch = {best_epoch}')

#Attempt to use Hybrid CNN + LSTM:
from tensorflow.keras.layers import Conv1D, MaxPooling1D
class AdvancedRNNModel(IntermediateRNNModel):
    def __init__(self, num_classes=3):
        super(AdvancedRNNModel, self).__init__(num_classes)
        self.conv = Conv1D(64, kernel_size=3, activation="relu", padding="same")
        self.pool = MaxPooling1D(pool_size=2)
        self.lstm = LSTM(64)
        self.hidden = Dense(64, activation="relu")
        self.output_layer = Dense(num_classes, activation="softmax")

    def call(self, inputs, training=False):
        x = self.conv(inputs)
        x = self.pool(x)
        x = self.lstm(x)
        if training:
            x = self.dropout1(x, training=training)
        x = self.hidden(x)
        x = self.bn(x, training=training)
        if training:
            x = self.dropout2(x, training=training)
        return self.output_layer(x)

#Compile
model4 = AdvancedRNNModel(num_classes=3)

model4.compile(
    loss="sparse_categorical_crossentropy",
    optimizer=Adam(learning_rate=0.002),
    metrics=["accuracy"]
)

#Training
history4 = model4.fit(
    X_train, y_train,
    epochs=100,
    batch_size=32,
    validation_split=0.2,
    callbacks=[es],
    verbose=1
)

#model accuracy
y_pred_4 = model4.predict(X_test)
y_pred_4 = np.argmax(y_pred_4, axis=1)

accuracy = accuracy_score(y_test, y_pred_4)
recall = recall_score(y_test, y_pred_4, average='weighted')
precision = precision_score(y_test, y_pred_4, average='weighted')
f1 = f1_score(y_test, y_pred_4, average='weighted')
print(f"Accuracy: {accuracy}")
print(f"Recall: {recall}")
print(f"Precision: {precision}")
print(f"F1 Score: {f1}")

#plot
plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
plt.plot(history4.history['loss'], label='Train Loss')
plt.plot(history4.history['val_loss'], label='Val Loss')
plt.title('Model with stacked LSTM, Bidirectional, 1D CNN Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

# Plot Accuracy
plt.subplot(1,2,2)
plt.plot(history4.history['accuracy'], label='Train Accuracy')
plt.plot(history4.history['val_accuracy'], label='Val Accuracy')
plt.title('Model with stacked LSTM, 1D CNN accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

best_epoch_4 = history4.history['val_accuracy'].index(max(history4.history['val_accuracy'])) + 1
plt.axvline(best_epoch_4, color='r', linestyle='--', label=f'Best Epoch = {best_epoch}')

import tensorflow as tf
from tensorflow.keras import Model
from tensorflow.keras.layers import Dense, Dropout, GRU, BatchNormalization, Conv1D, MaxPooling1D

# ------------------- Simple Attention -------------------
class AttentionLayer(tf.keras.layers.Layer):
    def __init__(self):
        super(AttentionLayer, self).__init__()

    def call(self, inputs):
        # Attention weights
        score = tf.nn.softmax(tf.reduce_sum(inputs, axis=-1, keepdims=True), axis=1)
        context = tf.reduce_sum(score * inputs, axis=1)
        return context

# ------------------- Advanced Base Model -------------------
class AdvancedRNNModel(Model):
    def __init__(self, num_classes=3):
        super(AdvancedRNNModel, self).__init__()
        self.conv = Conv1D(64, kernel_size=3, activation="relu")
        self.pool = MaxPooling1D(pool_size=2)
        self.dropout1 = Dropout(0.3)
        self.bn = BatchNormalization()
        self.dropout2 = Dropout(0.3)
        self.hidden = Dense(64, activation="relu")
        self.output_layer = Dense(num_classes, activation="softmax")

    def call(self, inputs, training=False):
        x = self.conv(inputs)
        x = self.pool(x)
        if training:
            x = self.dropout1(x, training=training)
        x = self.hidden(x)
        x = self.bn(x, training=training)
        if training:
            x = self.dropout2(x, training=training)
        return self.output_layer(x)

# ------------------- Very Advanced GRU + Attention -------------------
class VeryAdvancedRNNModel(AdvancedRNNModel):
    def __init__(self, num_classes=3):
        super(VeryAdvancedRNNModel, self).__init__(num_classes)
        self.gru = GRU(64, return_sequences=True)
        self.attention = AttentionLayer()

    def call(self, inputs, training=False):
        x = self.conv(inputs)
        x = self.pool(x)
        x = self.gru(x)
        x = self.attention(x)
        if training:
            x = self.dropout1(x, training=training)
        x = self.hidden(x)
        x = self.bn(x, training=training)
        if training:
            x = self.dropout2(x, training=training)
        return self.output_layer(x)

timesteps = X_train.shape[1]
num_features = X_train.shape[2]
model5 = VeryAdvancedRNNModel(num_classes=3)
model5.compile(
    loss="sparse_categorical_crossentropy",
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.002),
    metrics=["accuracy"]
)

model.build(input_shape=(None, timesteps, num_features))
model5.summary()

history5 = model5.fit(
    X_train, y_train,
    epochs=100,
    batch_size=32,
    validation_split=0.2,
    callbacks=[es],
    verbose=1
)

#accuracy
y_pred_5 = model5.predict(X_test)
y_pred_5 = np.argmax(y_pred_5, axis=1)

accuracy = accuracy_score(y_test, y_pred_5)
recall = recall_score(y_test, y_pred_5, average='weighted')

precision = precision_score(y_test, y_pred_5, average='weighted')
f1 = f1_score(y_test, y_pred_5, average='weighted')
print(f"Accuracy: {accuracy}")
print(f"Recall: {recall}")
print(f"Precision: {precision}")
print(f"F1 Score: {f1}")

#plot
plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
plt.plot(history5.history['loss'], label='Train Loss')
plt.plot(history5.history['val_loss'], label='Val Loss')
plt.title('Model with GRU Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

# Plot Accuracy
plt.subplot(1,2,2)
plt.plot(history5.history['accuracy'], label='Train Accuracy')
plt.plot(history5.history['val_accuracy'], label='Val Accuracy')
plt.title('Model with GRU accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

best_epoch_5 = history5.history['val_accuracy'].index(max(history5.history['val_accuracy'])) + 1
plt.axvline(best_epoch_5, color='r', linestyle='--', label=f'Best Epoch = {best_epoch}')

"""#Conclusion
EmbedMLP achieved the best results, outperforming traditional ML, RNN, and Transformer
models with a balanced performance across all credit classes.32
Transformer models were not ideal for tabular data due to their architecture, which expects
sequential or contextual relationships. They suffered from overfitting and unstable training
despite tuning.
RNN and LSTM architectures showed moderate success but were less effective for static
tabular data compared to feedforward approaches.
Traditional ML models (Logistic Regression, Decision Tree, SVM) underperformed,
highlighting the advantages of deep learning for complex, nonlinear credit data.
Data preprocessing (handling missing values, encoding categorical variables, and scaling
numeric features) was critical to model stability and accuracy.
Future improvements could focus on:
Feature engineering for the “Standard” credit class (where misclassification persisted),
Using hybrid architectures combining embeddings with attention,
Exploring ensemble approaches or explainable AI techniques for model transparency in
credit risk assessment.
"""